\chapter{Implementation}
\label{cha:Chapter5_Implementation}
\section{Test data}
\TODO{Zeitraum}
The test data contained human-annotated tweets provided by two different sources and covered a wide variety of topics. In total, 10,372 tweets were used, of which 1,776 were negative, 4,968 neutral, and 3,628 positive.

\subsection{SentiStrength}
SentiStrength is a data set constructed by Thelwall et al. to evaluate their SentiStrength algorithm, a lexicon-based classifier. They created data sets from multiple different sources including Twitter, BBC Forum, and other social media platforms. In this thesis, only the Twitter data set is used, which was labeled by one person \cite{10.1002/asi.21662}.

The data set contains three columns, an integer score of 1 to 5 for the positive score, a separate integer score of 1 to 5 for the negative score, and the tweet text. If a score is 1, it signifies that there is no sentiment, while a 5 signals a strong sentiment. \cite{10.1002/asi.21662}. Because a tweet can have both a considerable positive and negative score, an approach inspired by Saif et al. is used to convert it to a single polarity. A tweet is defined as positive if the positive score is at least 1.5 times higher than the negative one, and vice versa. If neither score is at least 1.5 greater, the tweet is classified as neutral \cite{oro40660}. This resulted in 947 negative, 1,959 neutral and 1,336 positive tweets.

\TODO{abgewandelte Version davon, wie zitieren?, topics?}

\subsection{SemEval2013}
According to Giachanou and Crestani, "SemEval (Semantic Evaluation) is an ongoing series of evaluations of computation semantic analysis systems" \cite[p.~28:31]{DBLP:journals/csur/GiachanouC16}. In 2013, they constructed multiple data sets for both training and testing. They defined two subtasks, subtask A to determine the sentiment based on the context of a marked word/phrase, and subtask B to detect the sentiment based on the entire message. Because this thesis looks at tweets as a whole without context, only the second data set is used \cite{nakov-etal-2013-semeval}.

The tweets were parsed based on popular topics that were identified earlier, and tweets that did not contain sentiment-bearing words were filtered out. Finally, the messages were annotated by five Amazon Mechanical Turk workers, for subtask B the polarity selected by the majority was chosen \cite{nakov-etal-2013-semeval}. As the data set only provided the tweet IDs and not the text, the Twitter API was used to crawl the text for each tweet. This was not possible for every tweet contained in the data set, as some were already deleted or otherwise not available. This resulted in 6,130 tweets, of which 829 were negative, 3,009 neutral and 2,292 positive.

\section{Lexicon-based Method}

\subsection{Lexicons}
In order to implement the word classes, four types of lexicons were used, which are explained in more detail here.

\subsubsection{Sentiment lexicon}
The lexicon containing sentiment words and their scores was chosen to be VADER, constructed by Hutto and Gilbert, which is a valence-based dictionary. \cite{DBLP:conf/icwsm/HuttoG14}. They created the lexicon by first gathering a list of common features in other lexicons, supplemented by additional features such as emoticons, acronyms, and slang. This list of 9000 features was then labeled by 10 independent human raters via Amazon Mechanical Turk on a scale of -4 to +4, with the average of all scores resulting in the final score. They removed all features whose score was zero and whose standard deviation was higher than 2.5, which resulted in a lexicon containing 7,500 features.

\subsubsection{Intensity lexicon}
For the intensifiers, the most common words from a list of English degree adverbs \cite{wiki:adverbs} were used and scored by a human rater. Amplifiers were given a rating above 1.0, while downtoners were given a rating between 0.0 and 1.0. For example, "almost" has a degree of 0.8, while "extremely" has a degree of 3.0.


\subsubsection{Negation lexicon}
For the negations, a list was constructed that contains the most common negations. The list is based on a blog entry by the company Grammarly \cite{negations}. In addition to the words itself, common spelling mistakes were included, such as a missing apostrophe for "isn't".

\subsubsection{Emoji Lexicon}
A lexicon constructed by Haak was used, which contains 198 emojis and their valence scores \cite{haak_dataset}. For example, the emoji "grinning face", which can be seen in Figure \ref{fig:emoji}, is assigned the positive score of +0.8. The score was calculated using the sentiment of tweets containing the emoji, which were classified using a lexicon-based method. Only emojis with more than ten occurrences and a standard deviation below 0.625 were considered. The score was then calculated as the mean sentiment of the associated tweets \cite{haak_article}.

\begin{figure}
    \centering
    \includegraphics[scale=0.05]{Images/emoji_smile.png}
    \caption{Grinning face emoji, \TODO{SOURCE}}
    \label{fig:emoji}
\end{figure}



\subsection{Algorithm}

An algorithm was designed to classify tweets, as seen in Algorithm \ref{lexiconAlg}. The tweet is first split using whitespace to separate each word. Then each word is pre-processed. First, punctuation is removed, unless the word consists of an emoticon/emoji. After each processing step, the word is searched in the sentiment lexicon, if the word is not found, the next step is used. Characters that appear more than two times in a row are reduced to two times. Additionally, characters are removed from the end of a word to prevent different word endings affecting the algorithm, up until a minimum word length of 3.

Taking into account the four different word classes, the most important parts of a tweet that define its sentiment were covered. The total score of a tweet is calculated by adding the score of each sentiment word. For each sentiment word, the previous two words are evaluated to see if there is an intensifier and/or a negation. If so, the polarity is adjusted accordingly. Additionally, if an emoji is detected, its sentiment is also added to the total score. The algorithm itself was implemented using Java.

\begin{algorithm}[]
  \caption{Lexicon algorithm}\label{lexiconAlg}
    \begin{algorithmic}[1]
        \Function{analyze}{$tweet$}\Comment{Sentiment score of tweet}
            \State $SentimentLexicon \gets Dictionary[word][sentiment]$
            \State $NegationList \gets$ List of negation words
            \State $IntensityLexicon \gets Dictionary[word][intensity]$
            \State $EmojiLexicon \gets Dictionary[emoji][emojiSentiment]$ 
            \State $score \gets 0.0$
            \ForEach {$word \in tweet$}
                \State $word =$ preprocess($word$)
                \If{$word \in SentimentLexicon$} 
                    \State $polarity \gets 1$
                    \ForEach {$previousWord \in$ previous two words}
                        \If{$previousWord \in NegationList$}
                            \State $polarity = polarity * (-1)$
                        \Else
                            \If{$previousWord \in IntensityLexicon$}
                                \State $polarity = polarity * intensity$
                            \EndIf
                        \EndIf
                    \EndFor
                    \State $score = score + polarity * sentiment$
                \Else
                    \If{$word \in EmojiLexicon$}
                        \State $score = score + emojiSentiment$
                    \EndIf
                \EndIf 
            \EndFor
            \State \textbf{return} $score$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\subsection{Discussion}
