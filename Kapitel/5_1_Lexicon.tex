\chapter{Implementation}
\label{cha:Chapter5_Implementation}
\section{Test data}
The test data contained human-annotated tweets provided by two different sources and covered a wide variety of topics. In total, 10,372 tweets were used, of which 1,776 were negative, 4,968 neutral, and 3,628 positive.

\subsection{SentiStrength}
SentiStrength is a data set constructed in 2012 by Thelwall et al. to evaluate the second version of their SentiStrength algorithm, a lexicon-based classifier. They created data sets from multiple different sources, including Twitter, BBC Forum, and other social media platforms. In this thesis, only the Twitter data set is used, which was labeled by one person \cite{10.1002/asi.21662}.

The data set contains three columns, an integer score of 1 to 5 for the positive score, a separate integer score of 1 to 5 for the negative score, and the tweet text. If a score is 1, it signifies that there is no sentiment, while a 5 signals strong sentiment. \cite{10.1002/asi.21662}. Because a tweet can have both a considerable positive and negative score, an approach inspired by Saif et al. is used to convert it to a single polarity. A tweet is defined as positive if the positive score is at least 1.5 times higher than the negative one and vice versa. If neither score is at least 1.5 greater, the tweet is classified as neutral \cite{oro40660}. This resulted in 947 negative, 1,959 neutral and 1,336 positive tweets.

\subsection{SemEval2013}
According to Giachanou and Crestani, "SemEval (Semantic Evaluation) is an ongoing series of evaluations of computation semantic analysis systems" \cite[p.~28:31]{DBLP:journals/csur/GiachanouC16}. In 2013, they constructed multiple data sets for both training and testing. They defined two subtasks, subtask A to determine the sentiment based on the context of a marked word/phrase, and subtask B to detect the sentiment based on the entire message. Because this thesis looks at tweets as a whole without context, only the second data set is used \cite{nakov-etal-2013-semeval}.

The tweets were parsed based on popular topics that were identified earlier from January 2012 to January 2013, and tweets that did not contain sentiment-bearing words were filtered out, to lower class imbalance. Finally, the messages were annotated by five Amazon Mechanical Turk workers, for subtask B the polarity selected by the majority was chosen \cite{nakov-etal-2013-semeval}. As the data set only provided the tweet IDs and not the text, the Twitter API was used to crawl the text for each tweet. This was not possible for every tweet contained in the data set, as some were already deleted or otherwise not available. This resulted in 6,130 tweets, of which 829 were negative, 3,009 neutral and 2,292 positive.

\section{Lexicon-based Method}

\subsection{Lexicons}
In order to implement the word classes, four types of lexicons were used, which are explained in more detail here.

\subsubsection{Sentiment lexicon}
The lexicon that contains sentiment words and their scores was chosen to be the valence-based dictionary VADER, constructed by Hutto and Gilber. They created the lexicon by first gathering a list of common features in other lexicons, supplemented by additional features such as emoticons, acronyms, and slang. This list of 9000 features was then labeled by 10 independent human raters via Amazon Mechanical Turk on a scale of -4 to +4, with the average of all scores resulting in the final score. They removed all features whose score was zero and whose standard deviation was higher than 2.5, which resulted in a lexicon containing 7,500 features \cite{DBLP:conf/icwsm/HuttoG14}.

\subsubsection{Intensity lexicon}
For the intensifiers, the most common words from a list of English degree adverbs \cite{wiki:adverbs} were used and scored by a human rater. Amplifiers were given a rating above 1.0, while downtoners were given a rating between 0.0 and 1.0. For example, "almost" has a degree of 0.8, while "extremely" has a degree of 3.0.


\subsubsection{Negation lexicon}
For the negations, a list was constructed that contained the most common negations. The list is based on a blog entry by the company Grammarly \cite{negations}. In addition to the words itself, common spelling mistakes were included, such as a missing apostrophe for "isn't".

\subsubsection{Emoji Lexicon}
A lexicon constructed by Haak was used, which contains 198 emojis and their valence scores \cite{haak_dataset}. For example, the emoji "grinning face", which can be seen in Figure \ref{fig:emoji}, is assigned the positive score of +0.8. The score was calculated using the sentiment of tweets containing the emoji, which were classified using a lexicon-based method. Only emojis with more than ten occurrences and a standard deviation below 0.625 were considered. The score was then calculated as the mean sentiment of the associated tweets \cite{haak_article}.

\begin{figure}
    \centering
    \includegraphics[scale=0.05]{Images/emoji_smile.png}
    \caption{Grinning face emoji, \TODO{SOURCE}}
    \label{fig:emoji}
\end{figure}



\subsection{Algorithm}

An algorithm was designed to classify tweets, as seen in Algorithm \ref{lexiconAlg}. Each tweet was first split using whitespace to separate each word. Then, each word was pre-processed. First, punctuation was removed, unless the word consisted of an emoticon/emoji. After each processing step, the word was searched in the sentiment lexicon; if the word was not found, the process continued with the next step. Characters that appeared more than two times in a row were reduced to two times, in order to prevent empathetic lengthening. Additionally, characters were removed from the end of a word to prevent different word endings from affecting the algorithm, up to a minimum word length of 3. One special case

Taking into account the four different word classes, the most important parts of a tweet that define its sentiment were covered. There is one special case which has to be considered. The used lexicons define "no" as both a sentiment word and a negation, which is why the algorithm checks whether a sentiment word appears after "no" to determine whether it is a negation or not. If it is a negation, the word is skipped.

The total score of a tweet was calculated by adding the score of each sentiment word. For each sentiment word, the previous two words were evaluated to see if there was an intensifier and/or a negation. If so, the polarity was adjusted accordingly. Additionally, if an emoji was detected, its sentiment was also added to the total score. The algorithm itself was implemented using Java.

Although this thesis focuses on polarity classification, the lexicon method was also able to return the strength of a given sentiment, as well as a neutral score of 0. A neutral score was only returned if no sentiment word could be detected or if the sum of detected sentiments was equal to 0.

\begin{algorithm}
  \caption{Lexicon-based algorithm used to return a positive, negative or neutral score for a given tweet.}\label{lexiconAlg}
    \begin{algorithmic}[1]
        \Function{analyze}{$tweet$}\Comment{Sentiment score of tweet}
            \State $SentimentLexicon \gets Dictionary[word][sentiment]$
            \State $NegationList \gets$ List of negation words
            \State $IntensityLexicon \gets Dictionary[word][intensity]$
            \State $EmojiLexicon \gets Dictionary[emoji][emojiSentiment]$ 
            \State $score \gets 0.0$
            \ForEach {$word \in tweet$}
                \State $word =$ preprocess($word$)
                \If{$word \in SentimentLexicon$} 
                 \If{$word ==$ "no"}
                        \ForEach {$nextWord \in$ next two words}
                        \If{$nextWord \in SentimentLexicon$}
                            \State Skip word
                        \EndIf
                        \EndFor
                \Else
                \State $polarity \gets 1$
                    \ForEach {$previousWord \in$ previous two words}
                        \If{$previousWord \in NegationList$}
                            \State $polarity = polarity * (-1)$
                        \Else
                            \If{$previousWord \in IntensityLexicon$}
                                \State $polarity = polarity * intensity$
                            \EndIf
                        \EndIf
                    \EndFor
                    \State $score = score + polarity * sentiment$
                \EndIf 
                \Else
                    \If{$word \in EmojiLexicon$}
                        \State $score = score + emojiSentiment$
                    \EndIf
                \EndIf 

            \EndFor
            \State \textbf{return} $score$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

