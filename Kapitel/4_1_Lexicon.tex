\chapter{Methodology}
\label{cha:Chapter4_Methodology}
The primary objective of this thesis is the implementation and evaluation of three different methods for sentiment analysis, more specifically, the task of sentiment polarity classification. The focus lies on binary classification, as this is the most commonly used implementation, especially for machine learning methods. Additionally, only the document/sentence level is considered. Due to Twitter's length restriction, the difference between the document and sentence level is diminished, as a tweet will often consist of only one sentence. Additionally, a tweet often concerns only a single entity, which can be identified by the presence of a word or hashtag \cite{DBLP:journals/csur/GiachanouC16}. To summarize, this thesis focuses on sentiment polarity classification on the document/sentence level.

\section{Lexicon-Based Method}
As mentioned earlier, lexicon-based methods rely on an algorithm to predict the sentiment of a tweet using one or multiple lexicons. One motivation for this approach outlined by Taboada et al. is domain independence. If a machine-learning classifier is trained using data from one single source, or one single type of source, it may affect which words the classifier deems as most significant. Taboada et al. analyzed the most important positive and negative features from a Support Vector Machine classifier trained on movie reviews. Among the most negative features were "2", "video", "tv" and "series". In a movie context, these features make sense, as sequel movies, as well as movies adapted from a video game or television series, are generally less liked. But if the classifier is to be domain-independent, these specific features are irrelevant or even misleading \cite{taboada}. Finn and Kushmerick looked at domain transfer by classifying documents assigned to a different topic from the one the machine learning classifier was trained on. While they achieved high accuracy for single-topic classification, the domain transfer resulted in much lower accuracy \cite{Finn03learningto}.

Another motivation is the ability to take context and sentence structure into account. For example, modifiers, such as negations and intensifiers, change the sentiment of the connected word and should be considered. In machine learning, bigrams can be applied to combine two words into a single feature, such as "not good", to learn the effect of certain combinations such as negations. While this is an improvement, negations often are not directly next to the sentiment word they affect, and the training data would need to contain a sizeable amount of different combinations to be able to use it as significant features \cite{taboada}.

In this thesis, the lexicon-based method uses four different word classes to calculate sentiment. The approach is based on sentiment words and their modifiers, in this case negations and intensifiers. Additionally, emojis are considered, as there is a high usage of emojis on Twitter. Because Twitter is an informal type of medium, words are preprocessed to prevent cases such as misspelling and empathetic lengthening from affecting the detection of sentiment words.

\subsection{Word Classes}
This chapter shortly explains each word class used and gives examples in order to showcase their use.

\subsubsection{Sentiment Words}
Sentiment words, also called opinion words, carry a positive or negative semantic orientation. Polarity-based lexicons only express whether a word is positive or negative, while a valence-based lexicon also determines the strength of a word. For example, a polarity-based lexicon would not differentiate between "bad" and "terrible", as both are negative, while a valence-based lexicon would establish "terrible" as having a stronger negative sentiment \cite{DBLP:conf/icwsm/HuttoG14}.

\subsubsection{Intensifiers}
Taboada et al., according to Quirk et al., name two types of intensifiers, amplifiers and downtoners. While amplifiers such as "very" increase the related sentiment, downtoners such as "barely" diminish it. Intensifiers should take the related sentiment into account and scale it accordingly \cite{taboada}.

\subsubsection{Negations}
Negations reverse the polarity of the corresponding sentiment, for example turning the positive sentiment "good" into the negative sentiment "not good". It is important though to note that negations do not necessarily appear right in front of the sentiment word they reverse, for example, an intensifier can be in between as in "not very good" \cite{taboada}.

\subsubsection{Emojis}
The Cambridge Dictionary defines an emoji as "a digital image that is added to a message in electronic communication in order to express a particular idea or feeling" \cite{cambridgeEmoji}. As Hu et al. found out, "the most popular intentions are expressing sentiment, strengthening expression, and adjusting tone" \cite[p.~109]{Hu_Guo_Sun_Nguyen_Luo_2017}. The use of emojis on Twitter has been steadily increasing, with 21.54\% of global tweets containing at least one emoji in the month of December 2021 \cite{emojiStatistic}. Thus, it is clear that emojis are an important part of a tweet's overall sentiment and need to be taken into consideration.







